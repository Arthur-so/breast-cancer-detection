{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "def get_subfolders_dictionary(root_path):\n",
    "    images_list = []\n",
    "    labels_dict = {}\n",
    "    current_label = 0\n",
    "\n",
    "    for subfolder in os.listdir(root_path):\n",
    "        if os.path.isdir(os.path.join(root_path, subfolder)):\n",
    "            images = [image for image in os.listdir(os.path.join(root_path, subfolder)) if image.endswith(('.jpg'))]\n",
    "            for img in images:\n",
    "\n",
    "                # Gerando um número único para cada nome da pasta de imagens\n",
    "                if subfolder in labels_dict:\n",
    "                    label = labels_dict[subfolder]\n",
    "                else:\n",
    "                    label = current_label\n",
    "                    labels_dict[subfolder] = label\n",
    "                    current_label += 1\n",
    "\n",
    "                # Lista irá conter dicionário com o nome da subpasta, nome da imagem e o label dela (int)\n",
    "                images_list.append({\"subfolder\": subfolder, \"img\": img, \"label\": label})\n",
    "    return images_list\n",
    "\n",
    "\n",
    "def split_dataset(images_list, train_ratio=0.8):\n",
    "\n",
    "    # Embaralhar os caminhos das imagens\n",
    "    random.shuffle(images_list)\n",
    "\n",
    "    # Calcular o tamanho do conjunto de treinamento\n",
    "    num_train = int(len(images_list) * train_ratio)\n",
    "\n",
    "    # Dividir os caminhos das imagens em conjuntos de treinamento e teste\n",
    "    train_set = images_list[:num_train]\n",
    "    test_set = images_list[num_train:]\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear cuda cache before starting:\n",
    "torch.cuda.empty_cache()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images_list, root_path, transform=None):\n",
    "        self.images_list = images_list\n",
    "        self.transform = transform\n",
    "        self.root_path = root_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_path, self.images_list[idx]['subfolder'], self.images_list[idx]['img'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = self.images_list[idx]['label']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def resnet18_data_preprocessing(images_list, root_path, batch_size=32, workers=2, device='cuda:0'):\n",
    "    # Define the standard size for ResNet18\n",
    "    RESNET18_RESIZE = 100\n",
    "    RESNET_NORMALIZE_VALUES = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    # Compose data transformations:\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((RESNET18_RESIZE, RESNET18_RESIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*RESNET_NORMALIZE_VALUES)\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = CustomImageDataset(images_list[0], root_path, transform=data_transforms)\n",
    "    test_dataset = CustomImageDataset(images_list[1], root_path, transform=data_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "    # Dataset sizes and class names\n",
    "    dataset_sizes = {'train': len(train_dataset), 'test': len(test_dataset)}\n",
    "    class_names = list(set(img['label'] for img in images_list[0] + images_list[1]))\n",
    "\n",
    "    # Config device\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return {'train': train_loader, 'test': test_loader}, dataset_sizes, class_names, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 160, 'test': 40}\n",
      "Class names: [0, 1]\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x00000292998AC190>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x00000292AC62BB20>}\n"
     ]
    }
   ],
   "source": [
    "# Preparação dos dados\n",
    "root_path = \"D:/Unifesp/IA/termografia/termography/dataset\"\n",
    "images_list = get_subfolders_dictionary(root_path)\n",
    "train_dataset, test_dataset = split_dataset(images_list)\n",
    "\n",
    "# Carregamento dos dados\n",
    "data_loaders, dataset_sizes, class_names, device = resnet18_data_preprocessing([train_dataset, test_dataset], root_path, batch_size=8, workers=0, device='cuda:0')\n",
    "\n",
    "print(\"Dataset sizes:\", dataset_sizes)\n",
    "print(\"Class names:\", class_names)\n",
    "print(data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, device, save_path, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    '''\n",
    "        Torch training loop:\n",
    "    '''\n",
    "\n",
    "    # Start timer:\n",
    "    since = time.time()\n",
    "    print('#################################################################################')\n",
    "    print(f'Start training model:')\n",
    "    print('#################################################################################')\n",
    "\n",
    "    # Initial values:\n",
    "    best_acc       = 0.0\n",
    "    best_loss      = 20.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Loop in number of epochs:\n",
    "    for epoch in range(num_epochs):\n",
    "        print('#################################################################################')\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('#################################################################################')\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            \n",
    "            print(f'Current Phase: {phase}.')\n",
    "            \n",
    "            model.train()  # Set model to training mode                \n",
    "\n",
    "            running_loss     = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data in dataloaders:\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward -> track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs  = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss     = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Update loss statistics\n",
    "                running_loss     += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            scheduler.step()\n",
    "                \n",
    "            ################################################################################################\n",
    "            # Calculate epoch loss:\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc  = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            # Iteration Output:\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            #################################################################################################\n",
    "           \n",
    "    # Training Iteration loop Completed: \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights and return:\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate  = 0.00045\n",
    "momentum       = 0.9\n",
    "lr_decay_gamma = 0.1\n",
    "lr_decay_step  = 7\n",
    "save_path      = root_path + \"/resnet18\"\n",
    "num_epochs     = 10\n",
    "\n",
    "\n",
    "# ResNet18  Fit Config:\n",
    "model_ft    = models.resnet18(pretrained=True)\n",
    "num_ftrs    = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model_ft    = model_ft.to(device)\n",
    "criterion   = nn.CrossEntropyLoss()\n",
    "\n",
    "# Parameters optimization:\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Learning Rate Decay by a factor of gamma every step_size epochs:\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=lr_decay_step, gamma=lr_decay_gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################################\n",
      "Start training model:\n",
      "#################################################################################\n",
      "#################################################################################\n",
      "Epoch 0/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.6088 Acc: 0.7000\n",
      "#################################################################################\n",
      "Epoch 1/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.3541 Acc: 0.8438\n",
      "#################################################################################\n",
      "Epoch 2/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.1425 Acc: 0.9813\n",
      "#################################################################################\n",
      "Epoch 3/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.1524 Acc: 0.9438\n",
      "#################################################################################\n",
      "Epoch 4/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0772 Acc: 0.9875\n",
      "#################################################################################\n",
      "Epoch 5/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0519 Acc: 0.9938\n",
      "#################################################################################\n",
      "Epoch 6/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0660 Acc: 0.9813\n",
      "#################################################################################\n",
      "Epoch 7/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0299 Acc: 1.0000\n",
      "#################################################################################\n",
      "Epoch 8/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0409 Acc: 0.9938\n",
      "#################################################################################\n",
      "Epoch 9/9\n",
      "#################################################################################\n",
      "Current Phase: train.\n",
      "train Loss: 0.0266 Acc: 1.0000\n",
      "Training complete in 0m 23s\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Training, model fit:\n",
    "model_ft = train_model(model_ft,\n",
    "                       data_loaders,\n",
    "                       dataset_sizes,\n",
    "                       device, \n",
    "                       save_path, \n",
    "                       criterion, \n",
    "                       optimizer_ft, \n",
    "                       lr_scheduler, \n",
    "                       num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_model(model, data_loader, device):\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Desabilita o cálculo do gradiente para economia de memória\n",
    "        for inputs, labels in data_loader['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calcula a precisão\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.00%\n",
      "Image 1 - Predicted: 0, Actual: 0\n",
      "Image 2 - Predicted: 0, Actual: 0\n",
      "Image 3 - Predicted: 0, Actual: 1\n",
      "Image 4 - Predicted: 0, Actual: 1\n",
      "Image 5 - Predicted: 0, Actual: 0\n",
      "Image 6 - Predicted: 0, Actual: 1\n",
      "Image 7 - Predicted: 0, Actual: 0\n",
      "Image 8 - Predicted: 0, Actual: 1\n",
      "Image 9 - Predicted: 0, Actual: 1\n",
      "Image 10 - Predicted: 0, Actual: 0\n",
      "Image 11 - Predicted: 0, Actual: 0\n",
      "Image 12 - Predicted: 0, Actual: 1\n",
      "Image 13 - Predicted: 0, Actual: 1\n",
      "Image 14 - Predicted: 0, Actual: 0\n",
      "Image 15 - Predicted: 0, Actual: 1\n",
      "Image 16 - Predicted: 0, Actual: 0\n",
      "Image 17 - Predicted: 0, Actual: 1\n",
      "Image 18 - Predicted: 0, Actual: 0\n",
      "Image 19 - Predicted: 0, Actual: 1\n",
      "Image 20 - Predicted: 0, Actual: 1\n",
      "Image 21 - Predicted: 0, Actual: 1\n",
      "Image 22 - Predicted: 0, Actual: 1\n",
      "Image 23 - Predicted: 0, Actual: 1\n",
      "Image 24 - Predicted: 0, Actual: 0\n",
      "Image 25 - Predicted: 0, Actual: 1\n",
      "Image 26 - Predicted: 0, Actual: 0\n",
      "Image 27 - Predicted: 0, Actual: 0\n",
      "Image 28 - Predicted: 0, Actual: 0\n",
      "Image 29 - Predicted: 0, Actual: 0\n",
      "Image 30 - Predicted: 0, Actual: 0\n",
      "Image 31 - Predicted: 0, Actual: 0\n",
      "Image 32 - Predicted: 0, Actual: 1\n",
      "Image 33 - Predicted: 0, Actual: 1\n",
      "Image 34 - Predicted: 0, Actual: 0\n",
      "Image 35 - Predicted: 0, Actual: 1\n",
      "Image 36 - Predicted: 0, Actual: 0\n",
      "Image 37 - Predicted: 0, Actual: 0\n",
      "Image 38 - Predicted: 0, Actual: 0\n",
      "Image 39 - Predicted: 0, Actual: 1\n",
      "Image 40 - Predicted: 0, Actual: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def infer_model(model, data_loader, device):\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Desabilita o cálculo do gradiente para economia de memória\n",
    "        for inputs, labels in data_loader['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calcula a precisão\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, all_preds, all_labels\n",
    "\n",
    "model_ft = model_ft.to(device)  # Move o modelo para o dispositivo\n",
    "\n",
    "# Realiza a inferência\n",
    "test_accuracy, test_preds, test_labels = infer_model(model_ft, data_loaders, device)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Opcional: mostra algumas predições\n",
    "for i in range(len(test_preds)):\n",
    "    print(f'Image {i+1} - Predicted: {test_preds[i]}, Actual: {test_labels[i]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
